<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Drone-assisted Road Gaussian Splatting with Cross-view Uncertainty">
  <meta name="keywords" content="Drone-assisted Road Gaussian Splatting with Cross-view Uncertainty">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>UC-GS</title>

  <!-- Bootstrap -->
  <link rel="stylesheet" href="./static/css/bootstrap-4.4.1.css">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  
  
  
  
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/72.png">

  

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/app.js"></script>
  <script src="./static/js/video_comparison.js"></script>
  <script src="./static/js/video_comparison_3.js"></script>

  <link rel="stylesheet" href="./static/css/dics.original.css">
  <link rel="stylesheet" href="./static/css/dics2.original.css">
  <script src="./static/js/event_handler.js"></script>
  <script src="./static/js/dics.original.js"></script>
  <script src="./static/js/dics2.original.js"></script>
  <script>
    function openDemo(demoName) {
      window.location = 'https://KevinSONG729.github.io/project-pages/SA-GS/demo/' + demoName + '.html';
    }
  </script>

</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title" style="margin-bottom: 0"><strong>Drone-assisted Road Gaussian Splatting with Cross-view Uncertainty</strong></h1>
          
          
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://sainingzhang.github.io">Saining Zhang</a><sup>*1,2</sup></span>
            <span class="author-block">
              Baijun Ye</a><sup>*1</sup></span>
            <span class="author-block">
              Xiaoxue Chen</a><sup>1</sup>
            </span>
            <br>
            <span class="author-block">
              <a href="https://tao-11-chen.github.io/">Yuantao Chen</a><sup>1</sup>
            </span>
            <span class="author-block">
              Zongzheng Zhang<sup>1</sup>
            </span>
            <span class="author-block">
              Cheng Peng<sup>1,3</sup>
            </span>
            <span class="author-block">
              Yongliang Shi<sup>1</sup>
            </span>
            <span class="author-block">
              <a href="https://sites.google.com/view/fromandto">Hao Zhao</a><sup>†1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Institute for AI Industry Research (AIR), Tsinghua University</span>
            <br>
            <span class="author-block"><sup>2</sup>Nanyang Technological University</span>
            <span class="author-block"><sup>3</sup>Beijing Institute of Technology</span>
          
            
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1uVSdYOXreEuntpswW3HXV-TypKi-ZopQ/view?usp=drive_link"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://arxiv.org/abs/2403.19615"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
          
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/SainingZhang/uc-gs/"
                   class="external-link button is-normal is-rounded is-dark disabled">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark disabled">
                  <span class="icon">
                      <i class="fas fa-database"></i>
                  </span>
                  <span>Dataset</span>
                  </a>
              </span>
  
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
      
          <video autoplay muted loop playsinline height="100%">
              <source src="resources/demo.mp4" type="video/mp4">
          </video>
        
      
          <h2 class="subtitle has-text-centered" style="margin-top: 15px">
            <b>TL;DR</b>: We introduce SA-GS, a training-free approach that can be directly applied to the inference process of any pretrained 3DGS model to resolve its visual artefacts at drastically changed rendering settings.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <!-- <h2 class="title is-3" style="margin-top: -20px">Motivation</h2> -->

        <img src="./resources/images/teaser.png" class="center">
        <div class="content has-text-justified">
          <p style="margin-top: 0px">
            Qualitative results of our Drone-assisted Road Gaussian Splatting with Cross-view Uncertainty and several baseline methods. 
          </p>
        </div>

      </div>
    </div>
    <!--/ Animation. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="margin-top: -30px">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Global and realistic rendering for large-scale road scenes is essential in autonomous driving simulation. 
            Recently, 3D Gaussian Splatting (3D-GS) has made groundbreaking progress in neural rendering, but the global 
            fidelity of large-scale road scene renderings is often limited by the input imagery, which usually has a 
            narrow field of view and focuses mainly on the street-level local area. Intuitively, the data from the drone's 
            perspective can provide a compensatory viewpoint for the data from the ground vehicle's perspective, enhancing 
            the completeness of scene reconstruction and rendering. However, training naively with aerial and ground images, 
            which exhibit significant view disparity, poses a significant challenge for 3D-GS due to its limited generalizability, 
            and does not demonstrate remarkable improvements in performance on road views. In order to enhance novel view synthesis 
            on road scene and to mitigate the adverse effects of aerial images, we design an uncertainty-aware  training method that 
            allows aerial images to assist in the reconstruction of areas where ground images have poor learning outcomes instead of weighting 
            all pixels equally in 3D-GS training like prior work did. We are the first to introduce the cross-view uncertainty to 3D-GS 
            by matching the car-view ensemble-based rendering uncertainty to aerial images, weighting the contribution of each pixel to 
            the training process. Additionally, to systematically quantify evaluation metrics, we assemble a high-quality synthesized 
            dataset comprising both aerial and ground images for road scenes. Through comprehensive results, we show that: 
            (1) Joint training aerial and ground images helps improve representation ability of 3D-GS when view shifting and 
            rotation, but performs poorly on held-out road view test. (2) Our method reduces the weakness of the joint 
            training, and outperforms other baselines quantitatively on both held-out tests and scenes involving view shifting and rotation on our datasets. 
            (3) Qualitatively, our method shows great improvements in the rendering of road scene details.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <!-- Paper video. -->
    <!--
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="margin-top: -20px">Motivation & Methods</h2>
        <br><br>
        <img src="./resources/images/pe.jpg" class="center">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            <b>Paradigm Comparison of Gaussian Rasterization Process.</b> All Gaussian Splatting methods share this framework for training and rendering, but different models
            use different strategies to process Gaussian primitives. Both 3DGS and Mip-Splatting suffer from scale inconsistency and need to modify the training procedure. 
            Our approach is training-free and only operates on the testing flow. We use <b>(d)</b> in pixel space to maintain the scale consistency of the Gaussian primitives, and
            further enhance the anti-aliasing capability of 3DGS by applying <b>(e)</b> and <b>(f)</b> to the α-blending process. Note that <b>(e)</b> and <b>(f)</b> only make sense with <b>(d)</b> activated.
          </p>
        </div>
        <br><br>
        <img src="./resources/images/drone-main.png" class="center">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            <b>Overview of Drone-assisted Road Gaussian Splatting with Cross-view Uncertainty.</b> We first adopt an ensemble-based rendering uncertainty to quantify the learning outcomes of 3D Gaussians on ground images. Next, the ground uncertainty is projected to the air to build the cross-view uncertainty. Subsequently, we introduce the cross-view uncertainty to the training of 3D Gaussians as weight for each pixel of aerial images in the loss function, together with the original rendering loss of 3D-GS for ground images.
          </p>
        </div>
        <img src="./resources/model_images/SI.png" class="center" width="50%">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            <b>Super Sampling and Integration applied on Gaussian.</b> Our super sampling method, denoted as <b>(a)</b>, involves dividing each pixel thread into 9 sub-pixels when
            traversing the base-ordered Gaussian within a tile. Each sub-pixel independently undergoes α-blending and weights the Gaussian spherical harmonic coefficient according
            to the sampling results. <b>(b)</b> is our integration method that diagonalizes the Gaussian covariance matrix by pixel rotation. This decomposes the integration result into the
            product of two marginal Gaussian distributions.
          </p>
        </div>

      </div>
    </div>
    <!--/ Animation. -->
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">

    <!-- Results. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Results</h2>
        <br>
        <h3 class="title is-4 has-text-centered">Comparison on Mip-NeRF 360 Dataset</h3>
        <p>We compare our method with Mip-Splatting and 3DGS in the zoom-out (first row) and zoom-in (second row) cases, respectively. Our method eliminates the dilation & erosion artefacts of 3DGS 
        under different rendering settings, while improving the jaggedness effect in the zoom-out case. Our method obtains results comparable with and beyond (zoom-out case) Mip-Splatting.</p>
        <div class="row_two_columns">
          <div class="content has-text-lefted">
            <video class="video" width="100%" id="xyalias1" loop playsinline autoplay muted src="resources/360_zoomout.mp4" onplay="resizeAndPlay3(this)" ></video>
            <canvas height=0 class="videoMerge" id="xyalias1Merge3"></canvas>
          </div>
          <div class="content has-text-righted">
            <video class="video" width="100%" id="xyalias11" loop playsinline autoplay muted src="resources/360_zoomin.mp4" onplay="resizeAndPlay3(this)" ></video>
            <canvas height=0 class="videoMerge" id="xyalias11Merge3"></canvas>
          </div>
        </div>
        
        <div class="container">
          <ul class="nav nav-tabs nav-fill nav-justified" id="object-scale-recon">
              <li class="nav-item">
                <a class="nav-link active" onclick="objectSceneEvent(0)">bicycle(1/8x)</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="objectSceneEvent(1)">room(1/8x)</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="objectSceneEvent(2)">kitchen(1/8x)</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="objectSceneEvent(3)">garden(8x)</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="objectSceneEvent(4)">counter(8x)</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="objectSceneEvent(5)">treehill(8x)</a>
              </li>
          </ul>
          <div class="b-dics" style="width: 1035px; font-weight: 600;margin:auto">
              <img src="resources/360_images/bicycle_48_raw.png" alt="3DGS">
              <img src="resources/360_images/bicycle_48_mip.png" alt="Mip-Splatting">
              <img src="resources/360_images/bicycle_48_sags_int.png" alt="SA-GS Integration (Ours)">
              <img src="resources/360_images/bicycle_48_sags_sup.png" alt="SA-GS Super Sampling (Ours)">
              <img src="resources/360_images/bicycle_48_gt.png" alt="GT">
          </div>
        </div>

        <br><br>
        <h3 class="title is-4 has-text-centered">Comparison on Blender Dataset</h3>
        <div class="content has-text-justified">
          <p>
            We show both zoom-out and zoom-in cases in different scenarios. We highlight the contrasting areas. Our method obtains robust anti-aliasing 
            performance improvements over 3DGS, while significantly outperforming Mip-Splatting in the zoom-out case.
          </p>
        </div>

        <div class="content has-text-centered">
          <video class="video" width="100%" id="xyalias12" loop playsinline autoplay muted src="resources/blender.mp4"></video>
          <canvas height=0 class="videoMerge" id="xyalias12Merge"></canvas>
        </div>

        <div class="container">
          <ul class="nav nav-tabs nav-fill nav-justified" id="ablation-3d-filter">
              <li class="nav-item">
                <a class="nav-link active" onclick="ablation3DEvent(0)">chair(1/8x)</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="ablation3DEvent(1)">ficus(1/8x)</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="ablation3DEvent(2)">ship(1/8x)</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="ablation3DEvent(3)">drum(8x)</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="ablation3DEvent(4)">hotdog(8x)</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="ablation3DEvent(5)">mic(8x)</a>
              </li>
          </ul>
          <div class="b-dics" style="width: 1000px; font-weight: 600;">
            <img src="resources/blender_images/chair_raw.png" alt="3DGS">
            <img src="resources/blender_images/chair_mip.png" alt="Mip-Splatting">
            <img src="resources/blender_images/chair_int.png" alt="SA-GS Integration (Ours)">
            <img src="resources/blender_images/chair_sup.png" alt="SA-GS Super Sampling (Ours)">
            <img src="resources/blender_images/chair_gt.png" alt="GT">
          </div>
        </div>

        <br><br>
        <h3 class="title is-4 has-text-centered">Effectiveness of 2D Scale-adaptive Filter</h3>
        <div class="content has-text-justified">
          <p>
            The 2D scale-adaptive filter maintains the consistency of the Gaussian distribution when zooming out, 
            which in turn fully unleashes the power of the integral and supersampling antialiasing methods. Additionally, 
            the filter removes erosion artifacts from the scene when zooming in, resulting in a more structurally uniform scene.
          </p>
        </div>
        <div class="row_two_columns">
          <div class="content has-text-lefted">
            <video class="video" id="filter_ablation_zoomout" loop playsinline autoplay muted src="resources/filter_abaltion_zoomout.mp4" onplay="resizeAndPlay3(this)" ></video>
            <canvas height=0 class="videoMerge" id="filter_ablation_zoomoutMerge3"></canvas>
          </div>
          <div class="content has-text-righted" type="width:100px;">
            <video class="video" id="xyalias23" loop playsinline autoplay muted src="resources/filter_ablation_zoomin.mp4" onplay="resizeAndPlay(this)" ></video>
            <canvas height=0 class="videoMerge" id="xyalias23Merge"></canvas>
          </div>
        </div>
      </div>
    </div>

  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{song2024sa,
      title={SA-GS: Scale-Adaptive Gaussian Splatting for Training-Free Anti-Aliasing},
      author={Song, Xiaowei and Zheng, Jv and Yuan, Shiran and Gao, Huan-ang and Zhao, Jingwei and He, Xiang and Gu, Weihao and Zhao, Hao},
      journal={arXiv preprint arXiv:2403.19615},
      year={2024}
    }</code></pre>
  </div>
</section>

<!-- <section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    ZY, AC and AG are supported by the ERC Starting Grant LEGO-3D (850533) and DFG EXC number 2064/1 - project number 390727645.
    TS is supported by a Czech Science Foundation (GACR) EXPRO grant (UNI-3D, grant no. 23-07973X).
    We also thank Christian Reiser for insightful discussions during the preparation of the draft.
  </div>
</section> -->

<!-- <section class="section" id="References">
  <div class="container is-max-desktop content">

        <h3 class="title is-4">References</h3>
        <div class="content has-text-justified">
          <ul>
            <li>
              <a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/" target="_blank">3D Gaussian Splatting for Real-Time Radiance Field Rendering</a>
            </li>
            <li>
              <a href="https://www.cs.umd.edu/~zwicker/publications/EWASplatting-TVCG02.pdf" target="_blank">EWA Splatting</a>
            </li>
          </ul>
        </div>
      </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
            This webpage template is from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. 
            We sincerely thank <a href="https://keunhong.com/">Keunhong Park</a> for developing and open-sourcing this template. 
            The video comparison with sliding bar is from <a href="https://dorverbin.github.io/refnerf/">Ref-NeRF</a>. 
            The image comparison with sliding bar is from <a href="https://research.nvidia.com/labs/dir/neuralangelo/">Neuralangelo</a>. 
          </p>
        </div>
      </div>
          <p></p>
        </div>
      </div>
</footer>

</body>
</html>
