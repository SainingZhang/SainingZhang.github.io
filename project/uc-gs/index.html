<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Drone-assisted Road Gaussian Splatting with Cross-view Uncertainty">
  <meta name="keywords" content="Drone-assisted Road Gaussian Splatting with Cross-view Uncertainty">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>UC-GS</title>

  <!-- Bootstrap -->
  <link rel="stylesheet" href="./static/css/bootstrap-4.4.1.css">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  
  
  
  
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/app.js"></script>
  <script src="./static/js/video_comparison.js"></script>
  <script src="./static/js/video_comparison_3.js"></script>

  <link rel="stylesheet" href="./static/css/dics.original.css">
  <link rel="stylesheet" href="./static/css/dics2.original.css">
  <script src="./static/js/event_handler.js"></script>
  <script src="./static/js/dics.original.js"></script>
  <script src="./static/js/dics2.original.js"></script>
  <script>
    function openDemo(demoName) {
      window.location = 'https://KevinSONG729.github.io/project-pages/SA-GS/demo/' + demoName + '.html';
    }
  </script>

</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title" style="margin-bottom: 0"><strong>Drone-assisted Road Gaussian Splatting with Cross-view Uncertainty</strong></h1>
          
          
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://sainingzhang.github.io">Saining Zhang</a><sup>*1,2</sup></span>
            <span class="author-block">
              Baijun Ye</a><sup>*1</sup></span>
            <span class="author-block">
              Xiaoxue Chen</a><sup>1</sup>
            </span>
            <br>
            <span class="author-block">
              <a href="https://tao-11-chen.github.io/">Yuantao Chen</a><sup>1</sup>
            </span>
            <span class="author-block">
              Zongzheng Zhang<sup>1</sup>
            </span>
            <span class="author-block">
              Cheng Peng<sup>1,3</sup>
            </span>
            <span class="author-block">
              Yongliang Shi<sup>1</sup>
            </span>
            <span class="author-block">
              <a href="https://sites.google.com/view/fromandto">Hao Zhao</a><sup>â€ 1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Institute for AI Industry Research (AIR), Tsinghua University</span>
            <br>
            <span class="author-block"><sup>2</sup>Nanyang Technological University</span>
            <span class="author-block"><sup>3</sup>Beijing Institute of Technology</span>
          
            
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1uVSdYOXreEuntpswW3HXV-TypKi-ZopQ/view?usp=drive_link"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://arxiv.org/abs/2403.19615"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
          
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/SainingZhang/uc-gs/"
                   class="external-link button is-normal is-rounded is-dark disabled">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark disabled">
                  <span class="icon">
                      <i class="fas fa-database"></i>
                  </span>
                  <span>Dataset</span>
                  </a>
              </span>
  
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
      
          <video autoplay muted loop playsinline height="100%">
              <source src="./resources/demo.mp4" type="video/mp4">
          </video>
        
      
          <h2 class="subtitle has-text-centered" style="margin-top: 15px">
            <b>TL;DR</b>: In this work, we introduce a novel uncertainty-aware training paradigm to effectively use aerial imagery to enhance the NVS of road views.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <!-- <h2 class="title is-3" style="margin-top: -20px">Motivation</h2> -->

        <img src="./resources/images/teaser.png" class="center">
        <div class="content has-text-justified">
          <p style="margin-top: 0px">
            Qualitative results of our Drone-assisted Road Gaussian Splatting with Cross-view Uncertainty and several baseline methods. 
          </p>
        </div>

      </div>
    </div>
    <!--/ Animation. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="margin-top: -30px">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Global and realistic rendering for large-scale road scenes is essential in autonomous driving simulation. Recently, 3D Gaussian Splatting (3D-GS) has made groundbreaking progress in neural rendering, but the global fidelity of large-scale road scene renderings is often limited by the input imagery, which usually has a narrow field of view and focuses mainly on the street-level local area. Intuitively, the data from the drone's perspective can provide a compensatory viewpoint for the data from the ground vehicle's perspective, enhancing the completeness of scene reconstruction and rendering. However, training naively with aerial and ground images, which exhibit significant view disparity, poses a significant convergence challenge for 3D-GS, and does not demonstrate remarkable improvements in performance on road views. In order to enhance the novel view synthesis of road views and to mitigate the adverse effects of aerial images, we design an uncertainty-aware training method that allows aerial images to assist in the synthesis of areas where ground images have poor learning outcomes instead of weighting all pixels equally in 3D-GS training like prior work did. We are the first to introduce the cross-view uncertainty to 3D-GS by matching the car-view ensemble-based rendering uncertainty to aerial images, weighting the contribution of each pixel to the training process. Additionally, to systematically quantify evaluation metrics, we assemble a high-quality synthesized dataset comprising both aerial and ground images for road scenes. Through comprehensive results, we show that: (1) Joint training aerial and ground images helps improve representation ability of 3D-GS when view shifting and rotation, but performs poorly on held-out road view test. (2) Our method reduces the weakness of the joint training, and outperforms other baselines quantitatively on both held-out tests and scenes involving view shifting and rotation on our datasets. (3) Qualitatively, our method shows great improvements in the rendering of road scene details. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <!-- Paper video. -->
    <!--
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="margin-top: -20px">Motivation & Methods</h2>
        <br><br>
        <img src="./resources/images/pe.jpg" class="center">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            <b>Results for training with ground or aerial and ground images on various models. </b> (G), (A+G) are training with ground or aerial and ground images.
            Incorporating aerial images helps to mitigate the decline in metrics of the road view synthesis after the view shifting and rotation compared with merely using ground data. However, aerial images do not enhance the result on the held-out test of road scene synthesis.
          </p>
        </div>
        <br><br>
        <img src="./resources/images/drone-main.png" class="center">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            <b>Overview of Drone-assisted Road Gaussian Splatting with Cross-view Uncertainty.</b> We first adopt an ensemble-based rendering uncertainty to quantify the learning outcomes of 3D Gaussians on ground images. Next, the ground uncertainty is projected to the air to build the cross-view uncertainty. 
            Subsequently, we introduce the cross-view uncertainty to the training of 3D Gaussians as weight for each pixel of aerial images in the loss function, together with the original rendering loss of 3D-GS for ground images.
          </p>
        </div>
        <img src="./resources/images/uncertainty.png" class="center" width="100%">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            <b>Visualization of the cross-view uncertainty.</b>
          </p>
        </div>

      </div>
    </div>
    <!--/ Animation. -->
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">

    <!-- Results. -->
   
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Results</h2>
        <br>
         <p>+1m is ascending 1 meter. 5Â°d is tilting down by 5 degrees. A* is HD aerial images. (G), (A+G) are training with ground or aerial and ground images.</p>
        <br>
        <h3 class="title is-4 has-text-centered">Comparison on NYC Dataset</h3>
        
        <div class="container">
          <ul class="nav nav-tabs nav-fill nav-justified" id="object-scale-recon">
              <li class="nav-item">
                <a class="nav-link active" onclick="objectSceneEvent(0)">1.5m</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="objectSceneEvent(1)">1.5+1m</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="objectSceneEvent(2)">1.5+1m5Â°d</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="objectSceneEvent(3)">1.8m</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="objectSceneEvent(4)">1.8+1m</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="objectSceneEvent(5)">1.8+1m5Â°d</a>
              </li>
          </ul>
          <div class="b-dics" style="width: 1035px; font-weight: 600;margin:auto">
              <img src="resources/results/NY155.png" alt="Scaffold-GS">
              <img src="resources/results/NY154.png" alt="Scaffold-GS(A+G)">
              <img src="resources/results/NY153.png" alt="Scaffold-GS(A*+G)">
              <img src="resources/results/NY152.png" alt="Ours">
              <img src="resources/results/NY151.png" alt="GT">
          </div>
        </div>

        <br><br>
        <h3 class="title is-4 has-text-centered">Comparison on Blender Dataset</h3>
        <div class="content has-text-justified">
          <p>
            We show both zoom-out and zoom-in cases in different scenarios. We highlight the contrasting areas. Our method obtains robust anti-aliasing 
            performance improvements over 3DGS, while significantly outperforming Mip-Splatting in the zoom-out case.
          </p>
        </div>

        <div class="content has-text-centered">
          <video class="video" width="100%" id="xyalias12" loop playsinline autoplay muted src="resources/blender.mp4"></video>
          <canvas height=0 class="videoMerge" id="xyalias12Merge"></canvas>
        </div>

        <div class="container">
          <ul class="nav nav-tabs nav-fill nav-justified" id="ablation-3d-filter">
              <li class="nav-item">
                <a class="nav-link active" onclick="ablation3DEvent(0)">chair(1/8x)</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="ablation3DEvent(1)">ficus(1/8x)</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="ablation3DEvent(2)">ship(1/8x)</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="ablation3DEvent(3)">drum(8x)</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="ablation3DEvent(4)">hotdog(8x)</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="ablation3DEvent(5)">mic(8x)</a>
              </li>
          </ul>
          <div class="b-dics" style="width: 1000px; font-weight: 600;">
            <img src="resources/blender_images/chair_raw.png" alt="3DGS">
            <img src="resources/blender_images/chair_mip.png" alt="Mip-Splatting">
            <img src="resources/blender_images/chair_int.png" alt="SA-GS Integration (Ours)">
            <img src="resources/blender_images/chair_sup.png" alt="SA-GS Super Sampling (Ours)">
            <img src="resources/blender_images/chair_gt.png" alt="GT">
          </div>
        </div>

        <br><br>
        <h3 class="title is-4 has-text-centered">Effectiveness of 2D Scale-adaptive Filter</h3>
        <div class="content has-text-justified">
          <p>
            The 2D scale-adaptive filter maintains the consistency of the Gaussian distribution when zooming out, 
            which in turn fully unleashes the power of the integral and supersampling antialiasing methods. Additionally, 
            the filter removes erosion artifacts from the scene when zooming in, resulting in a more structurally uniform scene.
          </p>
        </div>
        <div class="row_two_columns">
          <div class="content has-text-lefted">
            <video class="video" id="filter_ablation_zoomout" loop playsinline autoplay muted src="resources/filter_abaltion_zoomout.mp4" onplay="resizeAndPlay3(this)" ></video>
            <canvas height=0 class="videoMerge" id="filter_ablation_zoomoutMerge3"></canvas>
          </div>
          <div class="content has-text-righted" type="width:100px;">
            <video class="video" id="xyalias23" loop playsinline autoplay muted src="resources/filter_ablation_zoomin.mp4" onplay="resizeAndPlay(this)" ></video>
            <canvas height=0 class="videoMerge" id="xyalias23Merge"></canvas>
          </div>
        </div>
      </div>
    </div>

  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{song2024sa,
      title={SA-GS: Scale-Adaptive Gaussian Splatting for Training-Free Anti-Aliasing},
      author={Song, Xiaowei and Zheng, Jv and Yuan, Shiran and Gao, Huan-ang and Zhao, Jingwei and He, Xiang and Gu, Weihao and Zhao, Hao},
      journal={arXiv preprint arXiv:2403.19615},
      year={2024}
    }</code></pre>
  </div>
</section>

<!-- <section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    ZY, AC and AG are supported by the ERC Starting Grant LEGO-3D (850533) and DFG EXC number 2064/1 - project number 390727645.
    TS is supported by a Czech Science Foundation (GACR) EXPRO grant (UNI-3D, grant no. 23-07973X).
    We also thank Christian Reiser for insightful discussions during the preparation of the draft.
  </div>
</section> -->

<!-- <section class="section" id="References">
  <div class="container is-max-desktop content">

        <h3 class="title is-4">References</h3>
        <div class="content has-text-justified">
          <ul>
            <li>
              <a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/" target="_blank">3D Gaussian Splatting for Real-Time Radiance Field Rendering</a>
            </li>
            <li>
              <a href="https://www.cs.umd.edu/~zwicker/publications/EWASplatting-TVCG02.pdf" target="_blank">EWA Splatting</a>
            </li>
          </ul>
        </div>
      </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
            This webpage template is from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. 
            We sincerely thank <a href="https://keunhong.com/">Keunhong Park</a> for developing and open-sourcing this template. 
            The video comparison with sliding bar is from <a href="https://dorverbin.github.io/refnerf/">Ref-NeRF</a>. 
            The image comparison with sliding bar is from <a href="https://research.nvidia.com/labs/dir/neuralangelo/">Neuralangelo</a>. 
          </p>
        </div>
      </div>
          <p></p>
        </div>
      </div>
</footer>

</body>
</html>
